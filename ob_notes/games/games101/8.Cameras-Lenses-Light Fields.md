成像方法包括 **Synthesis合成成像** 和 **Capture捕捉成像**

1. Synthesis：raster | ray tracing 用合成的方法成像
2. Capture：用相机捕捉成像

# 一、相机

1. 针孔相机：小孔成像（场景全部都是清晰的）
2. Lens 透镜相机：透镜成像（场景在DOF范围内是清晰的）

## 1. 针孔相机

之前的光线追踪中用的相机就是针孔相机模型，渲染的结果得不到景深的效果（景深需要用到透镜成像）

![[8a5a81b83fa931be52e6dca81c6a576.jpg]]

在成像的过程中**一定要用到针孔/透镜**，否则如果直接将感光元件Sensor放到场景前面，Sensor上的每个像素点都会接收到来自**不同方向**上的光照信息，叠加起来就是**Irradiance**（没有方向性），结果就是**模糊**的，也就是说Sensor没法直接记录Radiance，需要通过小孔/透镜来辅助

## 2. 传感器 与 视场Field of View（FOV）

传感器sensor（感光元件）用来捕捉光线信息，与胶片film在渲染中不完全等价（film决定存储格式）

视场指的是相机**拍摄的范围**，其大小与**传感器大小**和**焦距**有关

* 传感器高度h
* 焦距f（Focal length）

![[Pasted image 20230615114621.png|500]]

通常**传感器大小固定**35mm，通过**改变焦距**来控制FOV大小（焦距越小，FOV越大），所以市面上买的单反镜头焦距不同

![[Pasted image 20230615114915.png|500]]

![[7f563681f545ceed86140b324f88db6.jpg]]

## 3. Exposure 曝光

曝光值 H = T * E

* T表示**曝光时间**：时间越长越亮（吸收光多），由**快门**控制
* E表示**Irradiance**：单位时间单位面积的光的能量大小，由**光圈**和**焦距**共同决定

| 感光元件      | 作用               |
| ------------- | ------------------ |
| 快门 Shutter  | 亮度、运动模糊     |
| 光圈 Aperture | 亮度、虚化（景深） |
| 感光度 ISO    | 亮度、噪点         |

![[Pasted image 20230615120700.png]]

### 1. Shutter 快门

> 快门是用来控制光线照射Sensor的**时间**的部件

1. 快门开放时间越长，接受光线就越多，照片越**亮**
2. 越长的曝光时间越容易出现**运动模糊**效果（时间上采样的反走样），也可能使物体出现**形变**（右图螺旋桨弯曲）
	* 快门打开有**一段时间**，这段时间内物体会运动，所以会出现运动模糊

![[Pasted image 20230615115807.png|300]] ![[Pasted image 20230615115820.png|300]]

### 2. Aperture 光圈

>光圈的大小可以控制Sensor的**受光量**，类似于人的瞳孔

1. 光圈越大，接受光越多，照片越**亮**
2. 光圈越大，场景越容易**模糊/虚化**

一般通过**F**数（F-number/F-stop）来表示光圈大小（通常写成FN或者F/N，其中的N才是光圈大小的值），可以理解为 $N=\frac{焦距f}{光圈直径d}$，**F数（N）越大，光圈越小**

![[Pasted image 20230615120031.png|500]]

### 3. ISO gain 感光度

> 感光度表示的是相机的Sensor**对光线的敏感程度**

相机感光元件对光线的敏感程度，感光度越高，敏感程度越高，照片越**亮**（同时对**噪声**的敏感程度也会增加，出现噪点）

一般为**后期处理**，对像素**亮度乘以某个值**，会对所有像素亮度放大

![[e6d8c5c6b96514f846b4a59ac76a4ce.jpg]]

### 4. 快门与光圈共同控制进光量

快门**速度**越快（亮度小），光圈**面积**越大（亮度大），才能保证进光量相对稳定，也就是说：进光量**正比于**$\frac{A}{Shutter Speed}\approx\frac{1}{F^2\cdot Shutter Speed}$（F越大，直径越小，光圈面积越小，进光少；Shutter Speed越小，快门越慢，进光多）

![[Pasted image 20230615122226.png|500]]

## 4. Fast and Slow Photography

### 1. 高速摄影

快门时间短+大光圈/大ISO（一般少用ISO）

![[09f2e4018e97fe7c8d286b23258ddb2.jpg]]

### 2. 延迟摄影

快门时间长+小光圈 -> 拉丝效果

![[67ea143a82e4d7e19c6753deef30564.jpg|300]] ![[ee2941bd3deaa19e2f6f6ba99d3bbcd.jpg|300]]

# 二、Thin Lens Approximation 薄透镜近似

理想透镜（无厚度）可将光线聚集一点——焦点

1. 平行光可过焦点
2. 过焦点的光可变平行
3. 可通过透镜组来改变焦距

![[74e8a206927551d48630ba6fb1ed7a1.jpg]]

## 1. 薄透镜方程

* f：焦距
* $z_o$：物体到镜面距离
* $z_i$：成像到镜面距离
* $\frac{1}{f} = \frac{1}{z_i}+\frac{1}{z_o}$

![[Pasted image 20230615101944.png]]

## 2. Defocus Blur 虚化（景深）

### 1. Computing Circle of Confusion（CoC）Size

> CoC就是物体的一个点在Sensor平面上呈现的圆的大小

* Focal Plane上的物体经过透镜后聚焦平面在Sensor Plane上，能清晰地显示
* Object远离Focal Plane，聚焦平面在Image上，光线继续直线传播，到Secsor Plane时从点变成了圆（CoC），导致模糊显示
* 最后得到C的大小（物体在Sensor Plane上呈现的圆的大小）/模糊程度与透镜/光圈大小A成正比：$C=A\frac{\|z_s-z_i\|}{z_i}=\frac{f}{N}\frac{\|z_s-z_i\|}{z_i}$

![[Pasted image 20230615103453.png]]

所以光圈越大（F数越小），越模糊；光圈越小，越清晰

![[Pasted image 20230615104357.png|500]]

### 2. Depth of Field 景深的定义

> 场景中能呈现出清晰的深度（最远距离-最近距离）

在Sensor附近成像的**CoC的大小在一定范围内**的距离Depth of focus所对应的**场景的深度Depth of Field**

![[Pasted image 20230615110841.png|500]]

* 中间的是透镜，左边的是场景，右边的是成像
* $D_F$为DOF对应的物体的最远距离，$D_S$为最适合距离，$D_N$为DOF对应的物体的最近距离：$DOF=D_F-D_N$
*  $d_F$为DOF对应的成像的最近距离，$d_S$为最适合距离，$d_N$为DOF对应的成像的最远距离

![[Pasted image 20230615111207.png]]

* Sensor离透镜越近，景深越大，远处越清晰
* 焦距f越大，景深越小，远处很多模糊
* **光圈**大小越小（F-number越大），景深越大（接近**小孔成像** -> 清晰）

## 3. Ray Tracing Ideal Thin Lenses 光线追踪中的薄透镜近似

我们之前的光线追踪都是假设相机为一个小点，默认为小孔成像，没有景深；现在可以模拟薄透镜来近似做出景深效果

1. 在Sensor平面内任选一个像素 x'
2. 在透镜lens plane上随机采样 x''（每个像素点要采样多个x''）
3. 根据x'的位置可以确定在物体平面上对应的点的位置 x'''
4. 将 x‘’ 和 x‘’‘连接起来即可得到物体点 x’‘’到透镜 x’‘的Radiance
5. 重复步骤2多次对同一个像素点在透镜上采样x’‘，**累加**Radiance得到最终像素点x’的结果

![[Pasted image 20230615105422.png|500]]

# 三、Light Field / Lumigraph 光场

![[Pasted image 20230616095348.png]]

* **光场**描述空间中任何一个**位置**往任何一个**方向**的**光的强度**
* **全光函数**用七维的信息来表示光场（人在不同位置往不同方向看到的信息）

![[6e2ee1f1db4e965769215f71e227e4d.jpg]]

## 1. 物体的光场

相机从不同的位置和不同的方向看向物体的不同位置，可以通过物体的**光场**来得到光线强度；而物体可以看作包围盒，只需要知道物体**前面的面**的不同位置往不同方向的光线强度即可

![[4e10fe5a59b6338f4be9652b1d41f8d.jpg|300]] ![[c4f85a3dcbf6843b78a863ccbdb3bfc.jpg|300]]

1. 光场就是对全光函数的采样（**子集**），通过**五维**信息表示光场：$P(\theta,\phi,V_x,V_y,V_z)$（少去了颜色 $\lambda$ 和时间 $t$ ）；
2. 通过**纹理映射坐标st**进一步简化位置信息，通过**四维**信息（平面st的二维位置信息+二维方向信息$\theta\phi$）就可以定义光场![[f761a0d1d8418e7f58c86e1027a4414.jpg|400]]
3. 通过**两个平行平面**（前面为st，后面为uv）来定义光场：两个平面上各自一个点连起来就可以表示光线的位置和方向![[a3b091dab2db98ac1aabe99b9b17d92.jpg|400]]

## 2. 相机的光场解释

* 将uv面看作是相机的位置，st面看作是环境
* **固定uv**平面上的一个点，往st平面看去，看到的就是环境的一个**完整的图**（st中的每个透镜中的结果就是原本的像素结果）
	* uv平面上的点就相当于相机的位置
* **固定st**平面上的一个点，往uv平面看去，也就等价于uv上不同点看向st平面上固定一个点，看到的是物体一个**像素点在不同位置**观测到的值

![[Pasted image 20230616100954.png]]


## 3. 光场相机

> 光场相机记录了环境的**整个环境的光场信息**，可以实现拍照后**移动相机位置**和**聚焦**

### 1. 将Irradiance分成Radiance存储

 每一个像素接收到的是环境各个方向上的光Irradiance，将像素的位置替换成透镜来将各个方向上的光Radiance分别存储（每个像素存储着各个方向的光，就如下图苍蝇的眼睛）
 
![[a3a16921f73028d170e4239200c3152.jpg]]

### 2. 光场相机的实现

* **普通相机**的Sensor中的每一个像素，存储的是**Irradiance**（物体上的点接收到的所有不同方向的光）
* **光场照相机**将原本的每个**像素换成了微透镜**（下图右边黄色的就是将原本的像素换成了透镜，出来的结果就是左图的每每个六边形，相当于**平面st**），将Irradiance各个方向的光分散到后面分别存储**Radiance**（从原本记录一个像素到现在**记录很多像素**，将这些像素合起来就是原本的一个像素，后面的面相当于**平面uv**）
* 原本拍摄一个物体的每一个点都是一个像素，存储的是Irradiance（也就是说原本黄色的位置就是物体的一个点，其左边是物体接收到的**不同方向的光线**），现在存储的是该点的所有**Radiance**，也就**相当于存储了物体的光场**
	* 对**所有透镜取同一个方向**的光线Radiance作为该像素的值，这就可以还原出相机在**不同方向**看到的图像结果（如下图相机看向上方）![[6f82ef73a929fa962dd518b7f89685f.jpg|300]]
	* 有了物体的光场，就可以模拟**移动相机**（往不同方向看物体），也就可以实现**背景虚化**（改变焦距，同时计算改变的光线）

![[Pasted image 20230616114251.png]]

* 缺点：
	1. 分辨率不足，每一个像素都相当于要记录一个像素组，分辨率通常较低
	2. 高成本，设计难
# 总结

1. 先从相机出发，介绍了相机的各个**部件**：**传感器Sensor**、**快门Shutter**、**光圈Aperture**、**ISO**及他们的作用
2. 然后又介绍了**薄透镜**，介绍了薄透镜方程：$\frac{1}{f} = \frac{1}{z_i}+\frac{1}{z_o}$，由薄透镜的聚焦问题引出了**虚化**出现原因（与光圈大小成正比），并根据不会出现虚化的范围引出了**景深**；
3. 根据薄透镜介绍了其在**光线追踪**中如何使用
4. 最后介绍了**光场**：先介绍了如何利用**物体的光场**看物体，再通过成像解析了**st和vt平面**，再引入**光场摄像机**（借助了st和vt的将Irradiance分解成Radiance的功能）