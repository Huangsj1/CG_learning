# Neural Reflectance Fields for Appearance Acquisition

这里做的事情主要有三个：

1. **解耦体渲染方程**：得到更细致的成分，这样就能够进行添加光线等操作
2. **简化 ray marching**：通过提出限制条件来简化 ray marching 过程
3. **预计算和存储 Transmittance**：这样实际预测时就能加快速度

## 1. Decouple Rendering Equation 解耦体渲染方程

由[[体渲染 Volune Rendering#2. 求体渲染方程 Volume Rendering Equation|体渲染方程]]中的式子 $(5)$ 中减去背景光项得到的常用体渲染方程（这也是NeRF中直接用的体渲染方程） $$L(\textbf{c},\pmb\omega_o)=\int_0^\infty\tau_{\textbf{c}}(\textbf{x})\ \sigma(\textbf{x})\ L_s(\textbf{x},\pmb\omega_o)\ dt\tag{1}$$ $$where\quad \tau_{\textbf{c}}(\textbf{x})=e^{-\int_0^t\sigma(\textbf{c}-u\pmb\omega_o)du}\tag{2}$$其中 $L_s(\textbf{x},\pmb\omega_o)$ 表示采样点 $\textbf{x}$ 的往 $\pmb\omega_o$ 方向的 radiance，它是由各个方向的radiance累计而来的：$$L_s(\textbf{x},\pmb\omega_o)=\int_Sf_p(\textbf{x},\pmb\omega_o,\pmb\omega_i)\ L_i(\textbf{x},\pmb\omega_i)\ d\pmb\omega_i\tag{3}$$其中 $\pmb\omega_o$ 表示采样点到相机的方向向量，$\pmb\omega_i$ 表示采样点到光源/各个方向的方向向量，$L_i(\textbf{x},\pmb\omega_i)$ 表示沿着 $\pmb\omega_i$ 方向的到达采样点 $\textbf{x}$ 的radiance，$f_p(\textbf{x},\pmb\omega_o,\pmb\omega_i)$ 表示 phase function（输入到单位面积的的E转换到特定方向$\omega_o$ 的比例函数）。这是论文中给出的式子，但是相较于[[5.Ray Tracing光线追踪#1. The Reflection Equation 反射方程|BRDF中的式子]]中少了 $cos\theta_i$（因为 $cos\theta_i$ 一般都放到了BRDF，即$f_r$的计算当中）。假设这只有**一个点光源**，$(3)$ 式化简为：$$L_s(\textbf{x},\pmb\omega_o)=f_r(\textbf{x},\pmb\omega_o,\pmb\omega_i,\textbf n(\textbf{x}),\textbf{R}(\textbf{x}))\ L_i(\textbf{x},\pmb\omega_i)\tag{4}$$其中 $f_r(\textbf{x},\pmb\omega_o,\pmb\omega_i,\textbf n(\textbf{x}),\textbf{R}(\textbf{x}))$ 为一个反射模型（类似于BRDF的$f_r$），接着将沿着 $\pmb\omega_i$ 方向的到达采样点 $\textbf{x}$ 的radiance $L_i(\textbf{x},\pmb\omega_i)$ 继续推导到点光源处：$$L_i(\textbf{x},\pmb\omega_i)=\tau_{\textbf{\ l}}(\textbf{x})\ L_{\textbf{l}}(\textbf{x})\tag{5}$$这里 $\textbf{l}$ 表示点光源位置，$L_{\textbf{l}}(\textbf{x})$ 表示光源点的光强，$\tau_{\ \textbf{l}}(\textbf{x})$ 表示光强从光源到当前位置的透射率transmittance。最终得到解耦的体渲染方程：$$L(\textbf{c},\pmb\omega_o)=\int_0^\infty\tau_{\textbf{c}}(\textbf{x})\ \sigma(\textbf{x})\ f_r(\textbf{x},\pmb\omega_o,\pmb\omega_i,\textbf n(\textbf{x}),\textbf{R}(\textbf{x}))\ \tau_{\textbf{\ l}}(\textbf{x})\ L_{\textbf{l}}(\textbf{x})\ dt\tag{6}$$这里将 $L_s(\textbf{x},\pmb\omega_o)$ ，也就是NeRF中的 $c$ 解耦成的 $(f_r,\tau_{\ \textbf{l}},L_\textbf{l})$ 

## 2. Ray Marching

将上述 $(6)$ 体渲染方程转换成离散形式（其中 $f_r(\textbf{x},\pmb\omega_o,\pmb\omega_i,\textbf n(\textbf{x}),\textbf{R}(\textbf{x}))$ 里面的参数太多，简单用 $f_r(\textbf{x}_j)$ 表示）

![[Pasted image 20230812115130.png]]![[Pasted image 20230812115154.png]]![[Pasted image 20230812115159.png]]

对于每一个像素点，都需要从**相机发出光线**沿着光线（下图蓝色线）采样得到采样点 $x_j$ 的体密度 $\sigma(\textbf{x}_k)$、累积的透射率 $\tau_{\textbf{c}}$；然后对于每个**采样点都往光源方向发散射光线**，并对这条（黄色光线）采样得到采样点的体密度$\sigma(\textbf{x}'_p)$ 、累计透射率 $\tau_{\textbf{l}}$；再结合 $f_r$ 和 $L_{\textbf{l}}$ 才能得到像素点的最终颜色。

这个过程需要知道 $\tau_{\textbf{c}}$、$\tau_{\ \textbf{l}}$、$\sigma(\textbf{x}_k)$、$\sigma(\textbf{x}'_p)$、$f_r$、$L_{\textbf{l}}$ 这些值才能体渲染处像素点颜色，其中 $\tau_{\textbf{c}}$ 和 $\tau_{\textbf{l}}$ 可以由 $\sigma(\textbf{x}_k)$、$\sigma(\textbf{x}'_p)$ 结合式子 $(8)(9)$得到，所以现在需要得到的是 $\sigma(\textbf{x}_k)$、$\sigma(\textbf{x}'_p)$、$f_r$、$L_{\textbf{l}}$ 。而且由于上述过程计算量非常大，所以这篇paper简化了很多过程：

1. **（唯一）点光源和相机在同一位置**（所有输入照片需要手机/相机开灯，且没有其他光照影响），这样就使得 $\tau_{\textbf{l}}=\tau_{\textbf{c}}$，减少了黄色光线的计算量，不用再计算 $\sigma(\textbf{x}'_p)$ 和 $\tau_{\textbf{l}}$
2. **光源 $L_{\textbf{l}}$ 的值已知**：将该参数作为已知超参数
3. **$f_r$ 使用microfacet BRDF模型**：$$f_r(\textbf{x},\pmb\omega_o,\pmb\omega_i,\textbf n(\textbf{x}),\textbf{R}(\textbf{x}))=k_d\frac{c}{\pi}+\frac{F(\pmb\omega_o,\textbf{n})G(\pmb\omega_i,\pmb\omega_o,\textbf{n})D(\textbf{n},\textbf{h})}{4(n,\pmb\omega_i)(n,\pmb\omega_o)}$$ [[BRDF Cook-Torrance|微表面的BRDF]]，其中将 $R$ 作为diffuse albedo漫反射反照率和specular rougnness 反射粗糙程度的组成，将 $n$ 作为法线分布，这样就可以根据microfacet BRDF模型得到 $f_r$ 输出

![[Pasted image 20230812120325.png]]

最终该网络用 $\textbf{x}=(x,y,z)$ 作为输入（实际也经过了类似NeRF的PE变换），输出 （体密度$\sigma$、法线$n$、反射属性$R$）。这里没有用到项NeRF一样将 $d$ 作为输入，因为已经解耦了体渲染方程，得到更本质的属性，可以通过**更精确的体渲染方程得到与方向无关的属性**（方向关系都只与 $\omega_i$ 和 $\omega_o$有关）

## 3. Adaptive Transmittance Volume 适应性透视率容量

对于训练好的网络，在预测新视角的时候依然需要对每个像素进行多次采样遍历网络才能得到结果，于是这里采取了一种 **pre-compute 预计算**的方法：对已经训练好的网络，通过记录**点光源在不同位置照射（也就是相机在不同位置）得到的经过coarse-to-fine的所有采样点的 Transmittance**，这样当预测新视角的时候，对于不同位置的相机/点光源可以通过直接查询和对采样点进行插值得到对应的 Transmittance。（这里说的应该是对于一个需要预测的点光源，插值最近的以存储的点光源的值，而这些已知的点光源又需要插值得到当前需要的采样点的值，相当于对光源和采样点插值）

下图展示了点光源在一个位置下经过coarse和fine网络采样得到的蓝色采样点，记录采样点透射率transmittance

![[Pasted image 20230812151204.png]]

## limitations 不足之处

1. 拍照时需要保证**相机和点光源放在一起**，且场景中没有其他光源（假定光源随机位置然后修正）
2. 没有**间接光照**
3. ray marching 过程太过**耗时**，而且如果1中不假设光源位置已知，则需要 ray marching 到光源处，计算量很大（如果已知光源那么可以预计算得到Transmittance；或者这里我可以用一个小网络来学习？）