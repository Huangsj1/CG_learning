# 一、[[NRF-2020]]

![[Pasted image 20230812120325.png]]

假设**只有一个点光源且点光源就在相机位置**，于是通过**经典体渲染方法**得到光线颜色

# 二、[[NeRV-2020]]

![[Pasted image 20230813161946.png]]
![[Pasted image 20230825184322.png]]

假设**光源已知**，用**网络来学习透射率/可见度visibility**，同时采取**直接光照+间接光照**来渲染得到更准确的结果，且**间接光照都通过取一个点**来计算

# 三、[[NeRD-2020]]

用**球面高斯函数SG来学习光照信息**，用**网络来学习BRDF的各种信息**，最终通过计算**期望点**来计算得到其radiance $L_o$ 来作为像素的颜色

![[Pasted image 20230815171337.png|500]]

# 四、[[Neural PIL-2021]]

用**环境光贴图来学习光照信息**，用**MLP网络Neural-PIL来学习[[Image Based Lighting]]中的预计算光照函数**，用**网络来学习BRDF信息**，且采用了**SMAE来学习BRDF的平滑信息**，最终用基于[[Image Based Lighting]]中的渲染方程得到像素颜色

![[Pasted image 20230817103453.png]]

# 五、[[NeRFactor-2021]]

用**环境贴图学习光照信息**，用**网络学习BRDF信息**，同时还用**网络学习visibility和法线来约束**直接根据体密度$\sigma$得到的visibility和法线是结果更准确，最后根据环境贴图得到渲染结果

![[Pasted image 20230817191207.png]]

# 六、[[NeILF-2022]]

不再学习光照，而**用网络来学习不同点不同方向的in-radiance** $L_i$，同时用**网络学习BRDF**，最后对物体表面的**期望点**经过渲染方程得到 $L_o$ 

![[Pasted image 20230818123126.png]]

# 七、[[NeILF++-2023]]

用[[VolSDF-2021]]中获得的几何信息来给[[NeILF-2022]]使用，同时保留了NeRF中原本的out-radiance来约束in-radiance，渲染过程同[[NeILF-2022]]

![[Pasted image 20230818173052.png]]

# 概括

虽然NeILF++思想较简单，效果也很好，且能够考虑到间接光照，但是其学习的固定的visibility和in/out-radiance都是固定的，当编辑物体的时候就需要重新训练；而像NeRD用SG函数模拟光照、Neural-PIL和NeRFactor用环境贴图来模拟光照，它们就可以很好地编辑物体来保留光照信息；但是它们都没有像NeRV一样考虑间接光照，所以或许最好的方法是学习光照信息、学习BRDF信息、同时也能够实现间接光照