# 一、[[Edit NeRF-2021]]

为**每个物体都学习其形状和颜色的latent code**，需要编辑的时候就**重新学习下面蓝色/黄色的参数**

![[Pasted image 20230821163615.png|500]]

# 二、[[ST-NeRF-2021]]

为**所有人和背景构建bounding-box**，并为**每个bounding-box提供一个ST-NeRF**来学习其在初始场景中的表现，最终一起渲染就可以得到像素图。在编辑的时候**对bounding-box进行仿射变换**，然后在渲染的时候就对对应的**bounding-box的坐标/方向进行逆仿射变换再传入ST-NeRF**中渲染

![[Pasted image 20230822143907.png]]

# 三、[[Object-NeRF-2021]]

将场景分成**背景和所有的物体**，为**每个物体提供一个可学习的object activation code**，渲染的时候对背景和所有的物体一起渲染合成得到最终结果。编辑的时候应该是**只学习object activation code**

![[Pasted image 20230822220905.png]]
![[Pasted image 20230822220925.png]]

# 四、[[NeRF-Editing-2022]]

将NeRF隐式表示转化为**显示Mesh表示**，编辑时**对Mesh进行编辑**，渲染的时候**根据显示Mesh的位置映射回编辑前的位置**来达到编辑的目的

![[Pasted image 20230824094444.png]]

# 五、[[NeRF-In-2022]]

预训练好NeRF，这里**编辑只有删除操作**，编辑时**用户只需提供一个视角下的修改的mask**，然后通过其他方法**获得其他视角下的masks**，通过这所有的masks来**得到对应视角的移除masks部分后的RGB图片和深度图**，之后用这些图片**重新训练NeRF网络**

![[Pasted image 20230823163420.png]]

# 六、[[DM-NeRF-2023]]

给定**所有像素点所属物体的标签**，除了学习NeRF外还学习一个**能预测3D空间中所有采样点的所属物体标签的Object Field网络**，将用户的编辑操作（平移、旋转、缩放）用**矩阵**表示，渲染的时候**对采样点进行逆矩阵的操作来得到原本的点**

![[Pasted image 20230824172232.png]]

# 七、[[SINE-2023]]

给定预训练的NeRF，编辑时**用户给定一张编辑后的图像**，通过**学习Editing Field中的几何和纹理两个网络**来学习编辑信息，并在最后**通过Color Compositing Layer层用CNN网络来合成**得到最终像素图

![[Pasted image 20230825114232.png]]

# 概括

上述编辑方法多种多样，要么像Edit NeRF一样重新训练部分网络和latent code；要么像object-NeRF一样直接学习latent code（这个不确定是不是）；要么像ST-NeRF、NeRF-Editing、DM-NeRF一样用逆变换思路直接将编辑后的点映射回编辑前的位置，或者像SINE一样用网络间接学习的方法映射回去；要么直接用已有的方法来得到多视角编辑后的图片来重新训练NeRF。个人感觉如果能将所有物体和场景分开训练，同时编辑的时候能恢复/影响其他物体（感觉主要是碰撞冲突和光照这方面要做好），这样场景会更加真实